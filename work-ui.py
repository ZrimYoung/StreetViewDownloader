# å¢åŠ å¤šæ‰¹æ¬¡å¤„ç†å’Œæ‰¹æ¬¡è¿›åº¦æ¡æ”¯æŒçš„ Google è¡—æ™¯å›¾åƒä¸‹è½½è„šæœ¬
# âœ… åŠŸèƒ½åŒ…æ‹¬ï¼š
#   - ä» CSV æ–‡ä»¶è¯»å–ç‚¹ä½ä¿¡æ¯
#   - ä½¿ç”¨ Google Maps API æ‰¹é‡è¯·æ±‚è¡—æ™¯å›¾åƒå¹¶æ‹¼æ¥
#   - æ”¯æŒé…ç½®æ–‡ä»¶è‡ªå®šä¹‰å‚æ•°
#   - ä¸‹è½½è¿›åº¦å¯è§†åŒ–ï¼ˆæ”¯æŒæ‰¹æ¬¡å’Œå•ç‚¹æ‹¼æ¥è¿›åº¦ï¼‰

import os
import json
import requests
import pandas as pd
from PIL import Image
from io import BytesIO
from time import sleep
from tqdm import tqdm, trange  # tqdmï¼šä¸»è¿›åº¦æ¡ï¼›trangeï¼šå›¾å—æ‹¼æ¥è¿›åº¦
from configparser import ConfigParser  # ç”¨äºè¯»å– INI é…ç½®æ–‡ä»¶

# ===== ä» configuration.ini è¯»å–å‚æ•° =====
config = ConfigParser()
with open('configuration.ini', 'r', encoding='utf-8') as f:
    config.read_file(f)  # åŠ è½½é…ç½®æ–‡ä»¶


# [PATHS] è·¯å¾„é…ç½®ï¼šè¾“å…¥/è¾“å‡º/æ—¥å¿—ç­‰è·¯å¾„
CSV_PATH = config['PATHS']['CSV_PATH']               # è¾“å…¥çš„ç‚¹ä½CSVæ–‡ä»¶è·¯å¾„
API_KEY_PATH = config['PATHS']['API_KEY_PATH']       # Google API Key æ–‡ä»¶è·¯å¾„
SAVE_DIR = config['PATHS']['SAVE_DIR']               # æ‹¼æ¥å›¾åƒä¿å­˜ç›®å½•
LOG_PATH = config['PATHS']['LOG_PATH']               # æˆåŠŸä¸‹è½½è®°å½•CSVè·¯å¾„
FAIL_LOG_PATH = config['PATHS']['FAIL_LOG_PATH']     # å¤±è´¥ä¸‹è½½è®°å½•CSVè·¯å¾„

# [PARAMS] ä¸‹è½½æ§åˆ¶å‚æ•°ï¼šæ‰¹æ¬¡æ•°ã€æ¯æ‰¹æ•°é‡ç­‰
BATCH_SIZE = int(config['PARAMS']['BATCH_SIZE'])     # æ¯æ‰¹ä¸‹è½½çš„ç‚¹ä½æ•°ä¸Šé™
NUM_BATCHES = int(config['PARAMS']['NUM_BATCHES'])   # æ‰¹æ¬¡æ•°é‡ï¼ˆå¾ªç¯å‡ è½®ï¼‰

# [TILES] å›¾å—é…ç½®å‚æ•°ï¼šæ‹¼æ¥è§†è§’ã€å°ºå¯¸ç­‰
ZOOM = int(config['TILES']['ZOOM'])                  # ç¼©æ”¾ç­‰çº§ï¼ˆ0~5ï¼‰
TILE_SIZE = int(config['TILES']['TILE_SIZE'])        # å›¾å—å°ºå¯¸ï¼ˆåƒç´ ï¼‰
TILE_COLS = int(config['TILES']['TILE_COLS'])        # æ¨ªå‘æ‹¼æ¥å›¾å—æ•°é‡
TILE_ROWS = int(config['TILES']['TILE_ROWS'])        # çºµå‘æ‹¼æ¥å›¾å—æ•°é‡
SLEEPTIME = float(config['TILES']['SLEEPTIME'])      # æ¯å¼ å›¾å—ä¹‹é—´çš„è¯·æ±‚å»¶è¿Ÿï¼ˆç§’ï¼‰

# ===== è¾“å‡ºå½“å‰æ‹¼æ¥å›¾åƒå‚æ•°ï¼ˆä¾¿äºç¡®è®¤è®¾ç½®ï¼‰ =====
print(f"ğŸ”§ å½“å‰è®¾ç½®ï¼šZOOM={ZOOM}, TILE_SIZE={TILE_SIZE}, TILE_COLS={TILE_COLS}, TILE_ROWS={TILE_ROWS}")
print(f"ğŸ–¼ï¸ é¢„æœŸæ‹¼æ¥å›¾åƒå¤§å°ï¼š{TILE_COLS * TILE_SIZE} x {TILE_ROWS * TILE_SIZE} åƒç´ ")

# ===== åˆå§‹åŒ–ä¿å­˜ç›®å½•å’Œ API å¯†é’¥ =====
os.makedirs(SAVE_DIR, exist_ok=True)  # å¦‚æœä¿å­˜ç›®å½•ä¸å­˜åœ¨å°±åˆ›å»º
with open(API_KEY_PATH, 'r') as f:
    API_KEY = f.readline().strip()  # è¯»å– Google Maps API Key

# ===== åˆå§‹åŒ–æ—¥å¿—è®°å½•ï¼ˆé¿å…é‡å¤ä¸‹è½½ï¼‰ =====
if os.path.exists(LOG_PATH):
    downloaded_ids = set(pd.read_csv(LOG_PATH)['ID'].astype(str))  # å·²ä¸‹è½½IDé›†åˆ
else:
    downloaded_ids = set()
    pd.DataFrame(columns=['ID']).to_csv(LOG_PATH, index=False)  # åˆ›å»ºç©ºæ—¥å¿—æ–‡ä»¶

if os.path.exists(FAIL_LOG_PATH):
    failed_df = pd.read_csv(FAIL_LOG_PATH)  # è¯»å–å¤±è´¥è®°å½•
else:
    failed_df = pd.DataFrame(columns=['ID', 'Reason'])  # åˆå§‹åŒ–å¤±è´¥æ—¥å¿—

# ===== åˆ›å»ºè¡—æ™¯ä¼šè¯ Tokenï¼Œä¾¿äºåç»­ API è¯·æ±‚å¤ç”¨ =====
session_payload = {
    "mapType": "streetview",
    "language": "en-US",
    "region": "US"
}
session_response = requests.post(
    f"https://tile.googleapis.com/v1/createSession?key={API_KEY}",
    headers={"Content-Type": "application/json"},
    json=session_payload
)
SESSION_TOKEN = session_response.json().get("session")
if not SESSION_TOKEN:
    print("âŒ æ— æ³•è·å– session tokenï¼Œå“åº”å†…å®¹ï¼š")
    print(session_response.text)
    raise Exception("æ— æ³•è·å– session tokenï¼Œè¯·æ£€æŸ¥ API Key æˆ– mapType è®¾ç½®")

# ===== è¯»å–å®Œæ•´ç‚¹ä½è¡¨ï¼Œå¹¶åŠ è½½æˆåŠŸè®°å½•è¡¨ =====
all_df = pd.read_csv(CSV_PATH)  # æ‰€æœ‰ç‚¹ä½
log_df = pd.read_csv(LOG_PATH)  # ä¸‹è½½æˆåŠŸè®°å½•

# ===== ä¸»å¾ªç¯ï¼šæ§åˆ¶å¤šæ‰¹æ¬¡ä¸‹è½½ =====
for batch_num in range(NUM_BATCHES):
    # è¿‡æ»¤å‡ºæœªä¸‹è½½çš„ç‚¹ä½ï¼ŒæŒ‰æ‰¹é‡æŠ“å–
    df = all_df[~all_df['ID'].astype(str).isin(downloaded_ids)].head(BATCH_SIZE)
    if df.empty:
        print("ğŸ‰ æ‰€æœ‰ç‚¹ä½å·²å¤„ç†å®Œæ¯•ï¼Œæ— éœ€å†è¿è¡Œæ›´å¤šæ‰¹æ¬¡ã€‚")
        break

    print(f"\nğŸš€ æ­£åœ¨å¤„ç†ç¬¬ {batch_num + 1}/{NUM_BATCHES} æ‰¹ï¼Œå…± {len(df)} ä¸ªç‚¹ä½...")

    # ä¸ºå½“å‰æ‰¹æ¬¡çš„ç‚¹ä½è·å–å¯¹åº” panoId
    locations = [{"lat": row["Lat"], "lng": row["Lng"]} for _, row in df.iterrows()]
    panoid_url = f"https://tile.googleapis.com/v1/streetview/panoIds?session={SESSION_TOKEN}&key={API_KEY}"
    response = requests.post(panoid_url, json={"locations": locations, "radius": 50})
    pano_ids = response.json().get("panoIds", [])
    print("ğŸ“ å·²è·å– panoIds")

    results = []  # å­˜å‚¨å½“å‰æ‰¹æ¬¡ç»“æœä¿¡æ¯

    # ===== éå†æ¯ä¸ªç‚¹ä½ï¼Œå¤„ç†æ‹¼æ¥ =====
    for i, (row, pano_id) in enumerate(tqdm(zip(df.itertuples(index=False), pano_ids), total=len(df), desc=f"æ‰¹æ¬¡ {batch_num + 1}"), start=1):
        if not pano_id:
            # æ—  panoId æƒ…å†µï¼Œè·³è¿‡å¹¶è®°å½•å¤±è´¥
            failed_df = pd.concat([failed_df, pd.DataFrame([{"ID": row.ID, "Reason": "No panoId"}])], ignore_index=True)
            continue

        # åˆ›å»ºä¸€å¼ ç©ºç™½å›¾åƒç”¨äºæ‹¼æ¥å…¨æ™¯
        panorama = Image.new('RGB', (TILE_SIZE * TILE_COLS, TILE_SIZE * TILE_ROWS))
        missing_tiles = 0  # ç¼ºå¤±å›¾å—è®¡æ•°å™¨
        total_tiles = TILE_COLS * TILE_ROWS

        # ===== ä¸‹è½½æ¯ä¸ªå›¾å—ï¼Œå¹¶é€ä¸€æ‹¼æ¥ï¼ˆå¸¦è¿›åº¦æ¡ï¼‰ =====
        for x in trange(TILE_COLS, desc=f"æ‹¼æ¥ {row.ID}", leave=False):
            for y in range(TILE_ROWS):
                tile_url = (
                    f"https://tile.googleapis.com/v1/streetview/tiles/{ZOOM}/{x}/{y}"
                    f"?session={SESSION_TOKEN}&key={API_KEY}&panoId={pano_id}"
                )
                tile_resp = requests.get(tile_url)
                if tile_resp.status_code == 200:
                    tile_img = Image.open(BytesIO(tile_resp.content))
                    panorama.paste(tile_img, (x * TILE_SIZE, y * TILE_SIZE))
                else:
                    missing_tiles += 1  # è‹¥ tile ç¼ºå¤±ï¼Œè®¡æ•°
                sleep(SLEEPTIME)

        # å¦‚æœå…¨éƒ¨å›¾å—éƒ½ç¼ºå¤±ï¼Œåˆ™è·³è¿‡ä¿å­˜
        if missing_tiles == total_tiles:
            failed_df = pd.concat([failed_df, pd.DataFrame([{"ID": row.ID, "Reason": "All tiles missing"}])], ignore_index=True)
            continue

        # ä¿å­˜æˆåŠŸæ‹¼æ¥çš„å›¾åƒ
        filename = f"{row.ID}_{pano_id}.jpg"
        filepath = os.path.join(SAVE_DIR, filename)
        try:
            panorama.save(filepath)
            results.append({"ID": row.ID, "panoId": pano_id, "file": filename})
            log_df = pd.concat([log_df, pd.DataFrame([{"ID": row.ID}])], ignore_index=True)
            downloaded_ids.add(str(row.ID))
        except Exception as e:
            # ä¿å­˜å¤±è´¥æƒ…å†µ
            failed_df = pd.concat([failed_df, pd.DataFrame([{"ID": row.ID, "Reason": str(e)}])], ignore_index=True)

    # ===== ä¿å­˜æ—¥å¿—ä¸ç»“æœ =====
    log_df.drop_duplicates().to_csv(LOG_PATH, index=False)
    failed_df.drop_duplicates().to_csv(FAIL_LOG_PATH, index=False)
    pd.DataFrame(results).to_csv(os.path.join(SAVE_DIR, f'results_batch_{batch_num+1}.csv'), index=False)

print("\nâœ… æ‰€æœ‰æ‰¹æ¬¡å¤„ç†å®Œæˆã€‚")